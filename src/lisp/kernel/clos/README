Like most CLOS implementations, Clasp's goes through some weirdness to have things work correctly with the MOP. These conceptual notes are intended to aid reading of the code, because comments can't do it all.

Of course, internals notes tend to not be updated, so it's possible the information here isn't accurate. It ought to be as of May 2020 (git commit hash 0af36ad3a9638a78028bcaab363addd4e19bbf44). Hopefully you're reading a file under version control, in which case you could try looking at the history of this directory to see if there have been any major changes since now.

Booting
=======

Classes and instances
---------------------

Defined in the conventional way, basically a pointer to the class, and a "rack", the vector of slots. Plus some other crap. Defined in core/instance.h. (FYI the rack is a separate vector rather than a stretchy part of the instance so that change-class can swap it out.)

After package.lisp, hierarchy.lisp is loaded. It defines variables containing specifications for the slot definitions of important standard classes. For example,

(defparameter +method-combination-slots+
 `((name :initarg :name :accessor method-combination-name)
   (compiler :initarg :compiler :accessor method-combination-compiler)
   (options :initarg :options :accessor method-combination-options)))

These are used to describe slots before slot definitions exist as objects. Particularly, std-slot-value.lsp defines WITH-EARLY-ACCESSORS and WITH-EARLY-MAKE-INSTANCE. The former defines local macros with the slot names that expand into direct instance references. For example,

(with-early-accessors (+method-combination-slots+) (method-combination-compiler mc))

would expand to

(macrolet ((method-combination-compiler (object) `(si::instance-ref ,object ,1)))
  (method-combination-compiler mc))

which is in turn equivalent to (si::instance-ref mc 1). This allows slot values to be accessed naturally without going through all the machinery of slot-value. Of course, it only works if slot locations don't change. It should probably use flet instead of macrolet, but local function inlining isn't working.

WITH-EARLY-MAKE-INSTANCE similarly makes instances without calling generic functions, using si::allocate-raw-instance and (setf si:instance-ref).

Some of the slot definitions are a little funny. standard-class has "class-id": this is unexported and nonstandard, but basically equivalent to class-name. I believe we don't use class-name because (setf class-name) is defined to call reinitialize-instance, which is inoperative during boot.

boot.lisp actually creates the classes in hierarchy.lisp - again, directly, using core:allocate-raw-class and with-early-accessors. It does this by looking at +class-hierarchy+ in hierarchy.lisp. Some classes are in there more than once - they are redefined.

After boot.lisp all standard classes are in their final states, i.e. no further bootstrap weirdness.

Generic functions
-----------------

Instances and classes are all defined relatively straightforwardly. This is not the case for generic functions. We rely on a few things to get the system up:

 * CLHS and MOP both have "restrictions on portable programs", basically that programs cannot redefine standard functions and methods, or extend them in certain difficult ways, without meeting undefined behavior. (Unfortunately, at present, we leave this behavior really undefined - could range from "extension is silently ignored" to "crash".)
 * Defining generic functions as simple functions performing only their standard behavior, and then later using these functions as the standard methods.
 * Satiation (explained below).

The generic dispatch uses the currently new technique we have optimistically called "fastgf". Fastgf has its own section below. The algorithm is more fully described in Strandh, R. (2014). Fast generic dispatch for Common Lisp. Proceedings of ILC 2014 on 8th International Lisp Conference - ILC 14. doi:10.1145/2635648.2635654

To set the system up, everything is defined with normal functions which we then convert into generics/methods/etc.

kernel.lisp defines a few important functions, some of which are used indefinitely, and some of which are redefined later.

 * ENSURE-GENERIC-FUNCTION will be redefined. This version uses with-early-make-instance.
 * The final standard method of COMPUTE-DISCRIMINATING-FUNCTION is defined here as a non-generic function. It only seems to be called as such by set-generic-function-dispatch, also in this file.
 * (SETF GENERIC-FUNCTION-NAME) checks *clos-booted*, calls reinitialize-instance if it's so, or else (setf slot-value).
 * The final standard method of COMPUTE-APPLICABLE-METHODS is defined here as a non-generic function.
 * The function that will be used as the primary method of COMPUTE-APPLICABLE-METHODS-USING-CLASSES is defined here, but not bound as the function.
 * A non-generic PRINT-OBJECT that simply uses print-unreadable-object is defined. This will be upgraded to a method later. It's defined earlier so that if you're unlucky enough to hit a problem during boot, instances can be printed.

method.lsp defines the final definition of DEFMETHOD. It also defines the final standard method of MAKE-METHOD-LAMBDA as a function, and defines early, non-generic versions of GENERIC-FUNCTION-METHOD-CLASS and ADD-METHOD. An early version of the internal function MAKE-METHOD (no relation to the local macro - it makes a method, like make-instance) is defined here. FIND-METHOD's final standard method is here defined as a function.

The early add-method stores information in *early-methods* for use in fixup.lisp. An alist (function-name . list-of-methods).

Note that all this adds up so that until these functions are redefined, DEFMETHOD forms don't require generic function calls at any time.

combin.lisp defines various early versions of COMPUTE-EFFECTIVE-METHOD and FIND-METHOD-COMBINATION. Also it installs the DEFINE-METHOD-COMBINATION macro, and all the simple standard ones.

slotvalue.lisp starts using DEFMETHOD, and thus defining generic functions as well.

standard.lisp defines (final) methods for most of the instance creation and initialization protocol. change.lisp does CHANGE-CLASS and REINITIALIZE-INSTANCE. stdmethod.lisp defines a few methods and stuff for methods.

generic.lisp defines DEFGENERIC and a few related things like ENSURE-GENERIC-FUNCTION-USING-CLASS.

fixup.lsp is what puts the system into the final mode, redefining early functions as methods, etc. Up to this point no generic functions have been called. First, fixup converts a few critical functions into methods early - the ones needed to compute a discriminating function. Then, all existing generic functions have a "specializer profile" set up. This is part of fastgf, and is simply a sequence indicating which required arguments are currently specialized on, and whether they are eql specialized.

With that done, we "satiate" critical generic functions. This is done in satiation.lisp. Satiation means setting up a fake call history with precomputed effective methods, for a few critical paths, namely the ones enabling discriminating functions to be computed. The full list is in satiate-standard-generic-functions. Satiation is done entirely without generic functions, using early-accessors and the primitive ungeneric functions for some things (e.g. compute-effective-method).

We also use the term "satiation" for the later operation that similarly sets up fake call histories for generic functions. But this is only done for optimization, whereas the satiation described above is critical to booting the system.

After satiation, add-direct-method is used to associate early methods with generic functions. Either it or method-specializers will be the first generic functions to actually be called, so you may run into problems here.

After that *early-methods* is unbound, so don't add any more methods until the final add-method is defined in a minute.

The final ENSURE-GENERIC-FUNCTION is installed next. It calls generic functions, so DEFGENERIC and DEFMETHOD after this will call generics.

Then a few things are redefined, most notably ADD-METHOD and REMOVE-METHOD, which are also immediately upgraded into methods. More stuff that should be inoffensive.

At the end of this file, CLOS is "set up" in that you should be able to manipulate generic functions with impunity. However some things like detailed PRINT-OBJECT are later.

Also note that "satiation" is done differently in the build from the final image. fixup.lsp is first loaded, which results in the process described above to get CLOS working. Then fixup.lsp is compiled. In this case the call histories and hopefully soon the discriminating functions are dumped into the fasl as described in "satiation" below, which means they don't have to be compiled (as much) as the system starts, which really helps startup time.

Operation
=========

Dispatch/fastgf
---------------

The code for fastgf, i.e. the implementation of discriminating functions, is spread among a few files. The runtime, so to speak, is in closfastgf.lsp. It uses the code generator defined in discriminate.lsp and the interpreter generator defined in dtree.lsp, and all of these use the "outcome" structures defined in outcome.lsp.

Basic dispatch technique is as follows. Each generic function has a "call history", which is a mapping from sequences of classes to "outcomes" (effective methods). The _direct_ classes of each instance that a generic function has methods specializing on (as recorded in the specializer profile) are checked against this call history, and if there is a match the matching outcome is branched to immediately. This is called the "fast path", because it can be completed extremely quickly (essentially just a memory read and a series of integer comparisons, as described below). If it's not present in the call history, a "dispatch miss" occurs; the dispatch miss code computes the outcome for that sequence of classes (through compute-applicable-methods, etc., as described in MOP), adds a new call history entry if possible, and then branches to the outcome. This is called the "slow path".

To quickly choose between paths based on the direct class of an instance, each class is given a natural number identifier called its "stamp", and each instance keeps it's direct class's stamp in its rack of slots for easy access. During discrimination, the instance stamp is checked against the set of stamps for the classes in the call history. This can be done as a quick multi-way branch, e.g. with a binary search.

C++ classes still have a stamp, but as the object does not have a rack it is stored elsewhere. Simpler classes, like CONS and FIXNUM, do not have stamps per se, and are tested for more conventionally by checking pointer tags.

For example, if A and B are subclasses of C, we have (defmethod foo ((x C) y) outcome0), the stamp of A is 7, and the stamp of B is 8, we could validly have any of the following fast paths:

(slow-path)

(let ((xs (core:instance-stamp x)))
  (if (= xs 7)
      outcome0
      (slow-path)))

(let ((xs (core:instance-stamp x)))
  (if (= xs 8)
      outcome0
      (slow-path)))

(let ((xs (core:instance-stamp x)))
  (if (>= xs 7)
      (if (<= xs 8)
          outcome0
          (slow-path))
      (slow-path)))

slow-path is an abbreviation for illustration - the real function is DISPATCH-MISS. Anyway, the point is it works based on the actual class of the instance, that is the class that the instance is a direct instance of.

For a new generic function, the "fast path" is always the first one, i.e. immediately goes to the slow path. The slow path does roughly what MOP suggests, that is, first it calls compute-applicable-methods-using-classes, and if that returns a second value of NIL it calls compute-applicable-methods. Then it uses the applicable methods to compute an effective method, and calls that.

If c-a-m-u-c returns a second value of T, the call is additionally "memoized". The list of classes of the required arguments is stored, along with the outcome, in the generic function's "call history". The discriminating function of the generic function is then recomputed to have the expanded fast path.

When c-a-m-u-c returns a second value of NIL, meaning for standard dispatch that there is a relevant eql-specialize method, the call can still be memoized in certain circumstances. First, the generic function must be a direct instance of standard-generic-function; this ensures that there are no custom methods on c-a-m-u-c, c-a-m, or anything. Second, any arguments in an eql-specialized position must match an eql specializer. To understand what this means and why this restriction is in place, consider (defmethod foo ((x symbol))) (defmethod foo ((x (eql 'x)))). If foo is called with, say, 'y, the argument does not match an eql specializer. If the call was memoized, it would be on the symbol class. Then, if foo was called later with 'x, the fast path would take it to the symbol outcome inappropriately. So instead, we only memoize the latter call (which is probably more common anyway) and leave the slow path for the former.

This situation could be improved by essentially memoizing multiple, mostly fictitious calls in the former case, to ensure all the eql specializers are covered. At this time I believe this is more trouble than its worth.

In short, the discriminating function is a static tree of class tests as you'd do without CLOS, but with only classes from actual arguments of previous calls rather than all possible argument combinations (which can grow combinatorically), and with some extra stuff so that you can define new methods and redefine classes yada yada.

That cache invalidation is really the tricky bit. When methods are added or removed, or the gf reinitialized, or classes redefined, or whatever, relevant call history entries are removed and the gf set to invalidated-dispatch-function. New calls with relevant arguments will hit the slow path, which will then reinstall a fixed fast path.

invalidated-dispatch-function sets the discriminating function to be the result of calculate-fastgf-dispatch-function, which is basically a compute-discriminating-function method (though the actual method just sets to invalidated-dispatch-function). calculate-fastgf-dispatch-function builds a fast path based on the call history. For example, for the above function FOO, it would compute the first if there was no call history, the second if the call history was one call with a fixnum, the third if the call history was one call with a bignum, and the last if the call history had both calls.

We go through this "invalidation" rather than recomputing the function immediately because it's common to define a few methods of a generic function in succession, and the function computed each time would be immediately discarded for the next except the last one. Waste of time.

Because of how all this works, compute-discriminating-function doesn't actually do much computing. This is perfectly conformant of course. Users can define compute-discriminating-function methods and bypass fastgf entirely. Note that compute-discriminating-function is called only where it has to be, e.g. in add-method, or reinitialization of a gf - not by fastgf itself, which uses invalidated-dispatch-function more directly.

Miscellany note: no-applicable-method is not memoized, because it's easy to pick off and not considered desirable- basically just clogging up the call history with crap. no-required-method is though, because it's a bit less trivial.

Outcomes
--------

In CLOS, the behavior of a generic function with whatever particular arguments is an "effective method". The effective method is, as described by CLOS, computed by the COMPUTE-EFFECTIVE-METHOD function. For optimization purposes, we deal with effective methods through special structure instances called "outcomes".

Each outcome contains the list of methods for which it is applicable, for caching purposes, and then specific information about the effective method. When the lists of applicable methods for two sequences of direct classes are identical, the same outcome is shared between the call history entries.

Note that this caching relies on the assumpion that COMPUTE-EFFECTIVE-METHOD is basically well behaved, in that if called with EQUAL method lists (and no redefinitions of the gf, etc. inbetween) it will return morally identical results. When I say "morally", it's because an effective method is a behavior, and the intuitive equivalence relation of behaviors is uncomputable. So if a programmer defines a COMPUTE-EFFECTIVE-METHOD method that use randomness or depend on the time of day or whatnot, fastgf won't pick it up. Given how often COMPUTE-EFFECTIVE-METHOD is specialized at all, let alone in such a pathological way, I think this is a reasonable condition to impose. We should document this better, though (FIXME).

Effective methods consisting of a call to a standard slot reader or writer method on a standard slot (explained below) are represented by optimized-slot-{reader,writer} outcomes. The outcome object contains the slot location along with some other things for debugging. It will be compiled into an inline instance reference, e.g. INSTANCE-REF which is specially compiled (i.e. not a function call). For the reader there is additionally a boundedness check.

"standard slot reader or writer" means that there is no possibility of a slot-value-using-class or (setf slot-value-using-class) method imposing other behavior - see static-gfs/README and static-gfs/svuc.lisp for a potential way to optimize even when there is customization. Note that we have to use the direct classes of arguments for all of this, not just the classes the accessor methods are specialized on, because slot locations can change with ineritance.

If there are no applicable methods, the outcome is not memoized (because it's probably just clutter). It is still computed, and consists of a effective-method-outcome that just calls NO-APPLICABLE-METHOD as per the standard.

If there is a lack of required methods - i.e. the method combination has some required method group, like PRIMARY in the standard combination, and it is found that no applicable methods are in this group - the outcome is memoized, just for lack of effort. It consists of a effective-method-outcome that calls NO-REQUIRED-METHOD.

The general case of an effective method that doesn't fit any of the above is represented by an effective-method-outcome. The object contains the effective method as a form, as well as a function implementing it.

Outcomes are computed by compute-outcome.

Computing applicable methods
----------------------------

Since fastgf knows the direct classes of instances when compiling effective methods, it's useful to do things specially based on these direct classes. The function FINAL-METHODS takes a list of methods as returned by compute-applicable-methods(-using-classes), and replaces them based on the list of direct classes. Currently replacements are only done for standard accessor methods on standard slots, though this could be extended.

Such accessors are replaced with instances of effective-reader-method or effective-writer-method, internal classes. These are like accessor methods but reocrd a slot location. Calls to these methods can be reduced to low level instance accesses.

Effective methods
-----------------

Anything other than simple accessor functions with no custom methods go through the general effective method interface in combin.lsp. effective-method-function accepts an effective method (form) and returns a function implementing it. It tries to avoid the compiler when computing this function by specially handling CALL-METHOD forms on standard methods.

An effective method function implements an effective method. Effective method functions accept (at least) the same parameters as the generic function. In order to reduce the use of APPLY and &rest consing, the parameters accepted by effective methods can be controlled lexically with the internal WITH-EFFECTIVE-METHOD-PARAMETERS macro, or dynamically by passing an ARG-INFO (check the comments in combin.lsp for that).

To organize the code better, and as an extension to MOP, Clasp expands CALL-METHOD forms into uses of an APPLY-METHOD macro. Unlike CALL-METHOD, APPLY-METHOD accepts an explicit spreadable argument list of arguments to the method. CALL-METHOD uses the WITH-EFFECTIVE-METHOD-PARAMETERS information to determine how to do this expansion. For example, if we have

(with-effective-method-parameters ((x0 x1) xr) (call-method #<METHOD 0> (#<METHOD 1> #<METHOD 2>)))

the CALL-METHOD will expand to (apply-method #<METHOD 0> ((#<METHOD 1> #<METHOD 2>)) x0 x1 xr).

APPLY-METHOD then calls the generic function EXPAND-APPLY-METHOD to expand. (Actually, if given a standard method it avoids an actual call for metacircularity reasons, but it works out the same.)

In the case that the effective method parameters don't need a &rest - which is the case if there are only required parameters - forms like (apply x ... nil) may be generated, and the compiler macro on APPLY can transmute these into direct funcalls.

Note that due to satiation (below), CALL-METHOD and APPLY-METHOD need to expand into dumpable forms.

Methods
-------

AMOP specifies that standard methods are called by calling their method functions with a list of arguments and list of next methods. But this entails APPLY and &rest list consing. As such Clasp tries to be a little smarter about things.

Provided there is no custom MAKE-METHOD-LAMBDA, the method function installed in a new method by DEFMETHOD will be an instance of the internal class %METHOD-FUNCTION. This is a funcallable instance whose instance function is an AMOP compatible function, so users can still use clos:method-function as they expect. However it has slots for a "fast" or "contf" method function.

"fast" method functions are used for methods that don't use call-next-method or next-method-p (as determined by a code walker). They are essentially just the original function pre-make-method-lambda. For example, for (defmethod foo ((x integer)) x), the fast method function would just be (lambda (x) x). (lambda (...) (apply-method #<method with fast function> (stuff) ...)) is equivalent to just the fast function, as next methods will be ignored, so fast functions can serve as effective method functions directly.

"contf" method functions are used for methods generally. They take the same arguments as an effective method function, plus one in the front, the "continuation". The "continuation" is an effective method function that essentially implements call-next-method with arguments. So for example, if we added (defmethod foo :around ((x integer)) (1+ (call-next-method))), this could have a contf function of (lambda (cont x) (1+ (funcall cont x))) (though right now we still bind a call-next-method function or macro or whatever, and we have to rebind parameters so call-next-method gets the originals). Then we can have for example (apply-method #<method with contf> ((#<method with fast>)) ...) expand to (apply #<contf> #<fast> ...).

To implement next-method-p, the continuation function will be an instance of %no-next-method-continuation, another funcallable instance, if there are no next methods. next-method-p can then just test the type of the continuation.

Satiation Interface
-------------------

The major downside of fastgf is that compiling the discriminating functions takes time, and this can occur at time, leading to inconsistencies in timing and stuff. And since for various reasons Clasp has an especially slow compiler, we really feel this pain. The way we soothe this is "satiation" - installing call histories into generic functions without actually compiling them. We also use satiation to boot up the system as described above, but we can use it for optimization too. (All the code is in satiation.lsp.)

As an example of the importance of this satiation, consider INITIALIZE-INSTANCE. Say it starts out with an empty call history. Then it's called to initialize something - a cleavir-ast:progn-ast object, say. This results in a dispatch miss followed by a discriminating function compilation. If it's then called with a cleavir-ast:car-ast object, there's another dispatch-miss and another compilation. Etc. etc., so every AST class results in another compile essentially the first time you try to use Cleavir. This causes a noticeable time lag, and the worse part is it's basically because fastgf is overeager - if it accumulated a call history of a few dozen classes, it could just compile once and be done.

Instead we start it out with a fake call history so that once it's compiled once, we're golden.

The interface to this is the CLOS:SATIATE function. The interface is described on the wiki but also here:

You call (CLOS:SATIATE generic-function ...lists of specializer designators...). A "specializer designator" is either a specializer, a symbol (the name of a class), or a list (eql <object>) representing an eql specializer for that (unevaluated) object. This adds to any existing call history by adding entries for the given specializer lists.

For the initialize-instance example, we would just do (clos:satiate #'initialize-instance '(cleavir-ast:progn-ast) '(cleavir-ast:car-ast) ...) and presto. (Obviously you only need specializers for the required parameters.)

As a bonus, if you have a literal (CLOS:SATIATE ...) form, a compiler macro will try to compute the call history at compile time, provided the generic function and all appropriate methods exist.

As a further extension that I'm still working on, the source of the discriminating function will appear in the compiler macroexpansion of CLOS:SATIATE, so that it isn't computed at load time at all. This requires coordination between the compiler and loader, because the stamp numbers have to appear literally in the code, meaning they have to be the same at compile-time and load-time. This may not be practical for non-internal code.

In order to support compile time satiation, Clasp extends the definition of similarity so that methods and eql specializers are dumpable. The make-load-form method on METHOD looks it up with FIND-METHOD, so it must be defined already in the image, and the generic function must have a proper name.

Interpreter
-----------

Another way of fighting the compiler is the "dtree interpreter". This is a C++ function living in funcallableInstance.cc that can serve as as funcallable instance function. It uses the same call history, outcomes, etc. as the fastgf algorithms described above, but it interprets the dtree rather than compiling a new discriminator when necessary. This can save time as compilation is avoided, at the expense of the discrimination itself being rather slower. Currently, we always use the interpreter for non-satiated functions, but this could be reconfigured to the other configuration: using the interpreter for functions until an arbitrary number (1024 at the moment) of calls are performed, at which point the compiler comes into play.

An interesting consequence of having the interpreter is that we could use the cleavir compiler for compiling discriminating functions. What we'd do is, when we hit a dispatch-miss, first put the interpreter into place, then compile the new discriminator. If the compilation recursively calls the function we're trying to compile a discriminator for, it will just use the interpreter and there will be no problem.

Compiler
--------

The discriminating function compiler is in discriminate.lsp. It works as described above, with the additional optimization that it can merge paths through the tree if they end at the same outcome. For example, if the call history consists of ((#(A B) . outcome0) (#(C B) . outcome0)), even if it tests the first argument first, it will use the same test code to test for B, saving some space.

The compiler can also inline effective methods into the discriminating function directly; this is controlled by the *inline-effective-methods* variable.

Static GFs (make-instance "ctors")
----------------------------------

See static-gfs/README.

Modification
============

Proceed with caution.

At the top of closfastgf is a thing putting :debug-fastgf in *features*. This is how you debug problems with generic function calls. There's a lot of output so it dumps it into a file in /tmp based on the PID. What it essentially does is log the dispatch miss "slow path" in which a generic function has to compute a new effective method etc.

If a function should be satiated but isn't, this will be represented in this log as infinite recursive calls, like "Dispatch miss for <whatever> ... Dispatch miss for <whatever> ..." This indicates that the dispatch miss code is itself trying to call the function. The solution is probably to throw the function into satiation.lsp. There is a recursion checker enabled when log-fastgf is on, but it might not always work.

Problems
========

It should basically work. There are a few conformance issues though, especially with the more obscure MOP use.

 * As mentioned, we let illegal modifications to standard functionality go through with nary a peep.
